{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile('cifar-10-python.tar.gz'):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            'cifar-10-python.tar.gz',\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 10\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data. The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    return x / 255\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # The possible values for labels are 0 to 9. 10 in total\n",
    "    return np.eye(10)[x]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    return tf.placeholder(tf.float32, shape=[None, *image_shape], name = \"x\")\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    return tf.placeholder(tf.float32, shape=[None, n_classes], name = \"y\")\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    return tf.placeholder(tf.float32, name=\"keep_prob\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # x_tensor.get_shape()\n",
    "    # >> (?, 32, 32, 5)\n",
    "    input_depth = x_tensor.shape[-1].value\n",
    "\n",
    "    weights = tf.Variable(\n",
    "        tf.truncated_normal(\n",
    "            shape=[\n",
    "                conv_ksize[0], # height\n",
    "                conv_ksize[1], # width\n",
    "                input_depth, # input_depth\n",
    "                conv_num_outputs # out_depth\n",
    "            ], \n",
    "            mean=0.0,\n",
    "            stddev=0.1\n",
    "        ),\n",
    "        name='weights'\n",
    "    )\n",
    "    bias = tf.Variable(tf.zeros(conv_num_outputs), trainable=True)\n",
    "    \n",
    "    # Apply a convolution to x_tensor using weight and conv_strides\n",
    "    conv_layer = tf.nn.conv2d(\n",
    "        x_tensor, \n",
    "        weights, \n",
    "        strides=[1, *conv_strides, 1], \n",
    "        padding='SAME'\n",
    "    )\n",
    "    \n",
    "    # Add bias\n",
    "    conv_layer = tf.nn.bias_add(conv_layer, bias)\n",
    "    \n",
    "    # Add a nonlinear activation to the convolution\n",
    "    conv_layer = tf.nn.relu(conv_layer)\n",
    "    \n",
    "    # Apply Max Pooling using pool_ksize and pool_strides\n",
    "    conv_layer = tf.nn.max_pool(\n",
    "        conv_layer, \n",
    "        ksize=[1, *pool_ksize, 1], \n",
    "        strides=[1, *pool_strides, 1], \n",
    "        padding='SAME'\n",
    "    )\n",
    "    \n",
    "    return conv_layer \n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # print(x_tensor.get_shape()[1:4].num_elements())\n",
    "    return tf.reshape(x_tensor, [-1, x_tensor.get_shape()[1:4].num_elements()])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    batch_size = x_tensor.shape[1].value\n",
    "    weights = tf.Variable(\n",
    "        tf.truncated_normal(\n",
    "            [batch_size, num_outputs],\n",
    "            mean = 0,\n",
    "            stddev=0.1)\n",
    "    )\n",
    "    bias = tf.Variable(tf.zeros(num_outputs))\n",
    "\n",
    "    fully_conn_layer = tf.matmul(x_tensor, weights)\n",
    "    fully_conn_layer = tf.nn.bias_add(fully_conn_layer, bias)\n",
    "    fully_conn_layer = tf.nn.relu(fully_conn_layer)\n",
    "\n",
    "    return fully_conn_layer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    batch_size = x_tensor.shape[1].value\n",
    "    weights = tf.Variable(\n",
    "        tf.truncated_normal(\n",
    "            [batch_size, num_outputs],\n",
    "            mean = 0,\n",
    "            stddev=0.1)\n",
    "    )\n",
    "    bias = tf.Variable(tf.zeros(num_outputs))\n",
    "    \n",
    "    output_layer = tf.matmul(x_tensor, weights)\n",
    "    output_layer = tf.nn.bias_add(output_layer, bias)\n",
    "    \n",
    "    return output_layer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    conv_num_outputs_layer1 = 32\n",
    "    conv_num_outputs_layer2 = 64\n",
    "    conv_num_outputs_layer3 = 128\n",
    "    fully_conn_num_outputs_layer_1 = 256\n",
    "    fully_conn_num_outputs_layer_2 = 512\n",
    "    conv_ksize = (5, 5)\n",
    "    conv_strides = (1, 1)\n",
    "    pool_ksize = (2, 2)\n",
    "    pool_strides = (2, 2)\n",
    "    \n",
    "    common_params = [conv_ksize, conv_strides, pool_ksize, pool_strides]\n",
    "    \n",
    "    # Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    conv_layer_1 = conv2d_maxpool(x, conv_num_outputs_layer1, *common_params)\n",
    "    conv_layer_1 = tf.nn.dropout(conv_layer_1, keep_prob)\n",
    "    \n",
    "    conv_layer_2 = conv2d_maxpool(conv_layer_1, conv_num_outputs_layer2, *common_params)\n",
    "    conv_layer_2 = tf.nn.dropout(conv_layer_2, keep_prob)\n",
    "    \n",
    "    conv_layer_3 = conv2d_maxpool(conv_layer_2, conv_num_outputs_layer3, *common_params)\n",
    "    conv_layer_3 = tf.nn.dropout(conv_layer_3, keep_prob)\n",
    "    \n",
    "    # Apply a Flatten Layer\n",
    "    flatten_layer_1 = flatten(conv_layer_3)\n",
    "\n",
    "    # Apply 1, 2, or 3 Fully Connected Layers\n",
    "    fully_conn_layer_1 = fully_conn(flatten_layer_1, fully_conn_num_outputs_layer_1)\n",
    "    fully_conn_layer_1 = tf.nn.dropout(fully_conn_layer_1, keep_prob)\n",
    "    fully_conn_layer_2 = fully_conn(flatten_layer_1, fully_conn_num_outputs_layer_2)\n",
    "    fully_conn_layer_2 = tf.nn.dropout(fully_conn_layer_2, keep_prob)\n",
    "    \n",
    "    \n",
    "    # Apply an Output Layer\n",
    "    num_outputs = 10 # 10 classes\n",
    "    output_layer = output(fully_conn_layer_2, num_outputs)\n",
    "    \n",
    "    return output_layer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    session.run(optimizer, feed_dict={x: feature_batch, y: label_batch, keep_prob: keep_probability})\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    loss = session.run(cost, feed_dict={x: feature_batch, y: label_batch, keep_prob: 1.0})\n",
    "    accuracy = session.run(accuracy, feed_dict={x: valid_features, y: valid_labels, keep_prob: 1.0})\n",
    "    print(\"Loss: {} Accuracy: {}\".format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 35\n",
    "batch_size = 128\n",
    "keep_probability = 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss: 2.1932835578918457 Accuracy: 0.22779998183250427\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss: 2.011131525039673 Accuracy: 0.31299999356269836\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss: 1.957720160484314 Accuracy: 0.3763999938964844\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss: 1.8524549007415771 Accuracy: 0.3917999863624573\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss: 1.7515805959701538 Accuracy: 0.4285999536514282\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss: 1.6449694633483887 Accuracy: 0.4553999900817871\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss: 1.6163479089736938 Accuracy: 0.465999960899353\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss: 1.5041940212249756 Accuracy: 0.48539993166923523\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss: 1.4849427938461304 Accuracy: 0.48159995675086975\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss: 1.4601508378982544 Accuracy: 0.4793999195098877\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss: 1.334553599357605 Accuracy: 0.5107999444007874\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss: 1.3120155334472656 Accuracy: 0.5133999586105347\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss: 1.1587424278259277 Accuracy: 0.5285999774932861\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss: 1.09547758102417 Accuracy: 0.5415999293327332\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss: 1.119186282157898 Accuracy: 0.5281999111175537\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss: 1.0606940984725952 Accuracy: 0.5435999035835266\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss: 0.9461108446121216 Accuracy: 0.5565999746322632\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss: 0.8634511232376099 Accuracy: 0.5571999549865723\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss: 0.875931978225708 Accuracy: 0.5637999176979065\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss: 0.7731307148933411 Accuracy: 0.5735999941825867\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss: 0.7171895503997803 Accuracy: 0.5747999548912048\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss: 0.6520981788635254 Accuracy: 0.5945999622344971\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss: 0.6261926293373108 Accuracy: 0.5879999399185181\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss: 0.5350332260131836 Accuracy: 0.5861998796463013\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss: 0.5346778631210327 Accuracy: 0.6061999201774597\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss: 0.4086195230484009 Accuracy: 0.5965999364852905\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss: 0.4407140612602234 Accuracy: 0.6021998524665833\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss: 0.3263455033302307 Accuracy: 0.6123998761177063\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss: 0.2961142361164093 Accuracy: 0.6095999479293823\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss: 0.2748626470565796 Accuracy: 0.6221998929977417\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss: 0.24453707039356232 Accuracy: 0.6201999187469482\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss: 0.2586561143398285 Accuracy: 0.6059998869895935\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss: 0.2022581845521927 Accuracy: 0.6185999512672424\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss: 0.19609764218330383 Accuracy: 0.6221999526023865\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss: 0.1641387790441513 Accuracy: 0.6179999113082886\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss: 2.2478585243225098 Accuracy: 0.22419998049736023\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss: 1.8837275505065918 Accuracy: 0.3407999873161316\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss: 1.6931178569793701 Accuracy: 0.366599977016449\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss: 1.6457328796386719 Accuracy: 0.43439996242523193\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss: 1.5777308940887451 Accuracy: 0.45159992575645447\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss: 1.6450750827789307 Accuracy: 0.48399996757507324\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss: 1.3891228437423706 Accuracy: 0.45259997248649597\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss: 1.2397334575653076 Accuracy: 0.49479997158050537\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss: 1.4911067485809326 Accuracy: 0.5090000033378601\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss: 1.3708136081695557 Accuracy: 0.5109999179840088\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss: 1.3920594453811646 Accuracy: 0.5313999652862549\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss: 1.1967368125915527 Accuracy: 0.5221999883651733\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss: 1.1225855350494385 Accuracy: 0.539199948310852\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss: 1.2587395906448364 Accuracy: 0.5643999576568604\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss: 1.2642561197280884 Accuracy: 0.5647999048233032\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss: 1.1507940292358398 Accuracy: 0.5829999446868896\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss: 1.0789107084274292 Accuracy: 0.5377998948097229\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss: 0.9628630876541138 Accuracy: 0.5771998763084412\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss: 1.0709222555160522 Accuracy: 0.5817999243736267\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss: 1.0804729461669922 Accuracy: 0.5877999067306519\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss: 1.0380303859710693 Accuracy: 0.6127999424934387\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss: 0.9688418507575989 Accuracy: 0.6031998991966248\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss: 0.8632034063339233 Accuracy: 0.6093999147415161\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss: 0.973716676235199 Accuracy: 0.6333999037742615\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss: 0.885626494884491 Accuracy: 0.6373998522758484\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss: 0.9440181851387024 Accuracy: 0.6339998841285706\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss: 0.9215208888053894 Accuracy: 0.6327998638153076\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss: 0.8347591757774353 Accuracy: 0.6157999634742737\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss: 0.7886825799942017 Accuracy: 0.6541998386383057\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss: 0.844180166721344 Accuracy: 0.6445999145507812\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss: 0.7575644254684448 Accuracy: 0.6627998948097229\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss: 0.8091502785682678 Accuracy: 0.6409999132156372\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss: 0.6821871995925903 Accuracy: 0.6525998711585999\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss: 0.7780335545539856 Accuracy: 0.6579998731613159\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss: 0.6754856705665588 Accuracy: 0.665199875831604\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss: 0.8035699129104614 Accuracy: 0.6637998819351196\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss: 0.7641209959983826 Accuracy: 0.6587998867034912\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss: 0.5282308459281921 Accuracy: 0.6653998494148254\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss: 0.6674501895904541 Accuracy: 0.6865999102592468\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss: 0.6420197486877441 Accuracy: 0.6791999340057373\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss: 0.6222699880599976 Accuracy: 0.7009998559951782\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss: 0.6511884927749634 Accuracy: 0.6747998595237732\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss: 0.4982835352420807 Accuracy: 0.6953999400138855\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss: 0.6109545230865479 Accuracy: 0.7005998492240906\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss: 0.7144730091094971 Accuracy: 0.6653998494148254\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss: 0.5636800527572632 Accuracy: 0.697399914264679\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss: 0.4850624203681946 Accuracy: 0.6937997937202454\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss: 0.38418346643447876 Accuracy: 0.6987997889518738\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss: 0.5332787036895752 Accuracy: 0.707399845123291\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss: 0.600462019443512 Accuracy: 0.7145998477935791\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss: 0.48435676097869873 Accuracy: 0.7241998910903931\n",
      "Epoch 11, CIFAR-10 Batch 2:  Loss: 0.39974018931388855 Accuracy: 0.7073997855186462\n",
      "Epoch 11, CIFAR-10 Batch 3:  Loss: 0.3301633596420288 Accuracy: 0.7287998199462891\n",
      "Epoch 11, CIFAR-10 Batch 4:  Loss: 0.4790204167366028 Accuracy: 0.7131999135017395\n",
      "Epoch 11, CIFAR-10 Batch 5:  Loss: 0.5108460783958435 Accuracy: 0.7161998152732849\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss: 0.4638007581233978 Accuracy: 0.7155998349189758\n",
      "Epoch 12, CIFAR-10 Batch 2:  Loss: 0.421169638633728 Accuracy: 0.7217998504638672\n",
      "Epoch 12, CIFAR-10 Batch 3:  Loss: 0.32230204343795776 Accuracy: 0.7313998341560364\n",
      "Epoch 12, CIFAR-10 Batch 4:  Loss: 0.4071316123008728 Accuracy: 0.726999819278717\n",
      "Epoch 12, CIFAR-10 Batch 5:  Loss: 0.4177444577217102 Accuracy: 0.7243998646736145\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss: 0.38347697257995605 Accuracy: 0.7397997975349426\n",
      "Epoch 13, CIFAR-10 Batch 2:  Loss: 0.3650006353855133 Accuracy: 0.7129998207092285\n",
      "Epoch 13, CIFAR-10 Batch 3:  Loss: 0.25890564918518066 Accuracy: 0.7389998435974121\n",
      "Epoch 13, CIFAR-10 Batch 4:  Loss: 0.39913707971572876 Accuracy: 0.7439998388290405\n",
      "Epoch 13, CIFAR-10 Batch 5:  Loss: 0.4226728677749634 Accuracy: 0.7411998510360718\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss: 0.3483855426311493 Accuracy: 0.7387999296188354\n",
      "Epoch 14, CIFAR-10 Batch 2:  Loss: 0.2951708436012268 Accuracy: 0.7397997975349426\n",
      "Epoch 14, CIFAR-10 Batch 3:  Loss: 0.1989605873823166 Accuracy: 0.7523998022079468\n",
      "Epoch 14, CIFAR-10 Batch 4:  Loss: 0.35702818632125854 Accuracy: 0.7369998097419739\n",
      "Epoch 14, CIFAR-10 Batch 5:  Loss: 0.3132578730583191 Accuracy: 0.7389998435974121\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss: 0.29422247409820557 Accuracy: 0.7419998645782471\n",
      "Epoch 15, CIFAR-10 Batch 2:  Loss: 0.27029815316200256 Accuracy: 0.7449998259544373\n",
      "Epoch 15, CIFAR-10 Batch 3:  Loss: 0.19292709231376648 Accuracy: 0.7603998184204102\n",
      "Epoch 15, CIFAR-10 Batch 4:  Loss: 0.28725340962409973 Accuracy: 0.7583998441696167\n",
      "Epoch 15, CIFAR-10 Batch 5:  Loss: 0.2921523451805115 Accuracy: 0.7461997866630554\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss: 0.23765446245670319 Accuracy: 0.7583998441696167\n",
      "Epoch 16, CIFAR-10 Batch 2:  Loss: 0.2199307680130005 Accuracy: 0.7453998327255249\n",
      "Epoch 16, CIFAR-10 Batch 3:  Loss: 0.15818116068840027 Accuracy: 0.7647998332977295\n",
      "Epoch 16, CIFAR-10 Batch 4:  Loss: 0.280930757522583 Accuracy: 0.7577998638153076\n",
      "Epoch 16, CIFAR-10 Batch 5:  Loss: 0.2315642237663269 Accuracy: 0.7577998042106628\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss: 0.23601774871349335 Accuracy: 0.7631998658180237\n",
      "Epoch 17, CIFAR-10 Batch 2:  Loss: 0.17594154179096222 Accuracy: 0.7579998970031738\n",
      "Epoch 17, CIFAR-10 Batch 3:  Loss: 0.16068536043167114 Accuracy: 0.7631998062133789\n",
      "Epoch 17, CIFAR-10 Batch 4:  Loss: 0.2726075351238251 Accuracy: 0.7471998333930969\n",
      "Epoch 17, CIFAR-10 Batch 5:  Loss: 0.16563448309898376 Accuracy: 0.7515998482704163\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss: 0.19974368810653687 Accuracy: 0.7559998035430908\n",
      "Epoch 18, CIFAR-10 Batch 2:  Loss: 0.15342597663402557 Accuracy: 0.7623998522758484\n",
      "Epoch 18, CIFAR-10 Batch 3:  Loss: 0.12634992599487305 Accuracy: 0.7649998664855957\n",
      "Epoch 18, CIFAR-10 Batch 4:  Loss: 0.16940076649188995 Accuracy: 0.7649998664855957\n",
      "Epoch 18, CIFAR-10 Batch 5:  Loss: 0.20089244842529297 Accuracy: 0.7655998468399048\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss: 0.13523614406585693 Accuracy: 0.7549998760223389\n",
      "Epoch 19, CIFAR-10 Batch 2:  Loss: 0.15686222910881042 Accuracy: 0.7529997825622559\n",
      "Epoch 19, CIFAR-10 Batch 3:  Loss: 0.11558765918016434 Accuracy: 0.757999837398529\n",
      "Epoch 19, CIFAR-10 Batch 4:  Loss: 0.2244413197040558 Accuracy: 0.7627997994422913\n",
      "Epoch 19, CIFAR-10 Batch 5:  Loss: 0.1549302488565445 Accuracy: 0.7653998732566833\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss: 0.10173415392637253 Accuracy: 0.7615997791290283\n",
      "Epoch 20, CIFAR-10 Batch 2:  Loss: 0.11553886532783508 Accuracy: 0.7665997743606567\n",
      "Epoch 20, CIFAR-10 Batch 3:  Loss: 0.12921208143234253 Accuracy: 0.7701997756958008\n",
      "Epoch 20, CIFAR-10 Batch 4:  Loss: 0.15447542071342468 Accuracy: 0.7665998339653015\n",
      "Epoch 20, CIFAR-10 Batch 5:  Loss: 0.1328590214252472 Accuracy: 0.7707998752593994\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss: 0.10821675509214401 Accuracy: 0.7651998400688171\n",
      "Epoch 21, CIFAR-10 Batch 2:  Loss: 0.09070709347724915 Accuracy: 0.7671998143196106\n",
      "Epoch 21, CIFAR-10 Batch 3:  Loss: 0.13414500653743744 Accuracy: 0.7503998279571533\n",
      "Epoch 21, CIFAR-10 Batch 4:  Loss: 0.13382379710674286 Accuracy: 0.7633997797966003\n",
      "Epoch 21, CIFAR-10 Batch 5:  Loss: 0.0911521166563034 Accuracy: 0.7737997770309448\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss: 0.11180008947849274 Accuracy: 0.7699998617172241\n",
      "Epoch 22, CIFAR-10 Batch 2:  Loss: 0.10556705296039581 Accuracy: 0.7609997987747192\n",
      "Epoch 22, CIFAR-10 Batch 3:  Loss: 0.08885900676250458 Accuracy: 0.7765998244285583\n",
      "Epoch 22, CIFAR-10 Batch 4:  Loss: 0.12025374174118042 Accuracy: 0.776999831199646\n",
      "Epoch 22, CIFAR-10 Batch 5:  Loss: 0.07065024971961975 Accuracy: 0.7683998346328735\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss: 0.0840025544166565 Accuracy: 0.7743998765945435\n",
      "Epoch 23, CIFAR-10 Batch 2:  Loss: 0.07973319292068481 Accuracy: 0.7641997933387756\n",
      "Epoch 23, CIFAR-10 Batch 3:  Loss: 0.07848314940929413 Accuracy: 0.7725998759269714\n",
      "Epoch 23, CIFAR-10 Batch 4:  Loss: 0.17174965143203735 Accuracy: 0.75139981508255\n",
      "Epoch 23, CIFAR-10 Batch 5:  Loss: 0.05778086557984352 Accuracy: 0.7831999063491821\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss: 0.0880860835313797 Accuracy: 0.7725998163223267\n",
      "Epoch 24, CIFAR-10 Batch 2:  Loss: 0.06120329722762108 Accuracy: 0.7691998481750488\n",
      "Epoch 24, CIFAR-10 Batch 3:  Loss: 0.09793127328157425 Accuracy: 0.773399829864502\n",
      "Epoch 24, CIFAR-10 Batch 4:  Loss: 0.1076919212937355 Accuracy: 0.7749998569488525\n",
      "Epoch 24, CIFAR-10 Batch 5:  Loss: 0.06611727923154831 Accuracy: 0.7779998779296875\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss: 0.05671758949756622 Accuracy: 0.7819998264312744\n",
      "Epoch 25, CIFAR-10 Batch 2:  Loss: 0.05209682509303093 Accuracy: 0.7791998386383057\n",
      "Epoch 25, CIFAR-10 Batch 3:  Loss: 0.06981603056192398 Accuracy: 0.7753998041152954\n",
      "Epoch 25, CIFAR-10 Batch 4:  Loss: 0.08790335059165955 Accuracy: 0.7765998840332031\n",
      "Epoch 25, CIFAR-10 Batch 5:  Loss: 0.04157699644565582 Accuracy: 0.7785998582839966\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss: 0.04922943934798241 Accuracy: 0.7849998474121094\n",
      "Epoch 26, CIFAR-10 Batch 2:  Loss: 0.0665821060538292 Accuracy: 0.7679998278617859\n",
      "Epoch 26, CIFAR-10 Batch 3:  Loss: 0.05838177353143692 Accuracy: 0.7725998163223267\n",
      "Epoch 26, CIFAR-10 Batch 4:  Loss: 0.06313947588205338 Accuracy: 0.7709999084472656\n",
      "Epoch 26, CIFAR-10 Batch 5:  Loss: 0.04845092073082924 Accuracy: 0.7835997343063354\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss: 0.07928922027349472 Accuracy: 0.7657998204231262\n",
      "Epoch 27, CIFAR-10 Batch 2:  Loss: 0.07249107956886292 Accuracy: 0.7605998516082764\n",
      "Epoch 27, CIFAR-10 Batch 3:  Loss: 0.048748262226581573 Accuracy: 0.7781998515129089\n",
      "Epoch 27, CIFAR-10 Batch 4:  Loss: 0.05908665060997009 Accuracy: 0.7711997628211975\n",
      "Epoch 27, CIFAR-10 Batch 5:  Loss: 0.039004817605018616 Accuracy: 0.7839998006820679\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss: 0.04055047035217285 Accuracy: 0.7797998189926147\n",
      "Epoch 28, CIFAR-10 Batch 2:  Loss: 0.05120241269469261 Accuracy: 0.7707998752593994\n",
      "Epoch 28, CIFAR-10 Batch 3:  Loss: 0.060802482068538666 Accuracy: 0.7725998163223267\n",
      "Epoch 28, CIFAR-10 Batch 4:  Loss: 0.05944879725575447 Accuracy: 0.78059983253479\n",
      "Epoch 28, CIFAR-10 Batch 5:  Loss: 0.02839808538556099 Accuracy: 0.7885997891426086\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss: 0.030118823051452637 Accuracy: 0.7879998683929443\n",
      "Epoch 29, CIFAR-10 Batch 2:  Loss: 0.03210212290287018 Accuracy: 0.7849997878074646\n",
      "Epoch 29, CIFAR-10 Batch 3:  Loss: 0.045216865837574005 Accuracy: 0.7693998217582703\n",
      "Epoch 29, CIFAR-10 Batch 4:  Loss: 0.06881881505250931 Accuracy: 0.7791998386383057\n",
      "Epoch 29, CIFAR-10 Batch 5:  Loss: 0.025423122569918633 Accuracy: 0.7837998270988464\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss: 0.0362873338162899 Accuracy: 0.7827997803688049\n",
      "Epoch 30, CIFAR-10 Batch 2:  Loss: 0.035676248371601105 Accuracy: 0.7807998657226562\n",
      "Epoch 30, CIFAR-10 Batch 3:  Loss: 0.052415356040000916 Accuracy: 0.7687998414039612\n",
      "Epoch 30, CIFAR-10 Batch 4:  Loss: 0.05106329172849655 Accuracy: 0.7867997884750366\n",
      "Epoch 30, CIFAR-10 Batch 5:  Loss: 0.026328323408961296 Accuracy: 0.7815998196601868\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss: 0.033422213047742844 Accuracy: 0.7833998799324036\n",
      "Epoch 31, CIFAR-10 Batch 2:  Loss: 0.03539246693253517 Accuracy: 0.7741998434066772\n",
      "Epoch 31, CIFAR-10 Batch 3:  Loss: 0.04775424301624298 Accuracy: 0.7797998189926147\n",
      "Epoch 31, CIFAR-10 Batch 4:  Loss: 0.041406869888305664 Accuracy: 0.7683998346328735\n",
      "Epoch 31, CIFAR-10 Batch 5:  Loss: 0.04309137165546417 Accuracy: 0.7801997661590576\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss: 0.027346407994627953 Accuracy: 0.7841998338699341\n",
      "Epoch 32, CIFAR-10 Batch 2:  Loss: 0.0142636988312006 Accuracy: 0.7827998399734497\n",
      "Epoch 32, CIFAR-10 Batch 3:  Loss: 0.03044021688401699 Accuracy: 0.7703998684883118\n",
      "Epoch 32, CIFAR-10 Batch 4:  Loss: 0.0318337082862854 Accuracy: 0.7889997959136963\n",
      "Epoch 32, CIFAR-10 Batch 5:  Loss: 0.020607806742191315 Accuracy: 0.7853997945785522\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss: 0.02937992289662361 Accuracy: 0.7833998203277588\n",
      "Epoch 33, CIFAR-10 Batch 2:  Loss: 0.021134966984391212 Accuracy: 0.7831997871398926\n",
      "Epoch 33, CIFAR-10 Batch 3:  Loss: 0.019134920090436935 Accuracy: 0.783599853515625\n",
      "Epoch 33, CIFAR-10 Batch 4:  Loss: 0.041045673191547394 Accuracy: 0.7767997980117798\n",
      "Epoch 33, CIFAR-10 Batch 5:  Loss: 0.019096646457910538 Accuracy: 0.7761998176574707\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss: 0.022560307756066322 Accuracy: 0.7819998264312744\n",
      "Epoch 34, CIFAR-10 Batch 2:  Loss: 0.026803821325302124 Accuracy: 0.7767997980117798\n",
      "Epoch 34, CIFAR-10 Batch 3:  Loss: 0.038166798651218414 Accuracy: 0.7761998176574707\n",
      "Epoch 34, CIFAR-10 Batch 4:  Loss: 0.024650346487760544 Accuracy: 0.7789998054504395\n",
      "Epoch 34, CIFAR-10 Batch 5:  Loss: 0.02045057713985443 Accuracy: 0.7833998799324036\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss: 0.030506327748298645 Accuracy: 0.7827998399734497\n",
      "Epoch 35, CIFAR-10 Batch 2:  Loss: 0.020501764491200447 Accuracy: 0.7871997952461243\n",
      "Epoch 35, CIFAR-10 Batch 3:  Loss: 0.019320465624332428 Accuracy: 0.7801998257637024\n",
      "Epoch 35, CIFAR-10 Batch 4:  Loss: 0.020084433257579803 Accuracy: 0.7863998413085938\n",
      "Epoch 35, CIFAR-10 Batch 5:  Loss: 0.011964945122599602 Accuracy: 0.7847998738288879\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.7771954113924051\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRERERCT6/yZoJSiqEbEsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f367be36f60>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_training.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for train_feature_batch, train_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: train_feature_batch, loaded_y: train_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Why 50-80% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
